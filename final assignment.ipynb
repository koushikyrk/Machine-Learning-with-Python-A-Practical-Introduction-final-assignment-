{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Import Libraries and Load Data\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             TEAM CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
      "0  North Carolina  ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
      "1       Wisconsin  B10  40  36  129.1   93.6   0.9758   54.8   47.7  12.4   \n",
      "2        Michigan  B10  40  33  114.4   90.4   0.9375   53.9   47.7  14.0   \n",
      "3      Texas Tech  B12  38  31  115.2   85.2   0.9696   53.5   43.0  17.7   \n",
      "4         Gonzaga  WCC  39  37  117.8   86.3   0.9728   56.6   41.1  16.2   \n",
      "\n",
      "   ...  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  windex  \n",
      "0  ...  53.9  44.6  32.7  36.2   71.7   8.6         2ND   1.0  2016       1  \n",
      "1  ...  54.8  44.7  36.5  37.5   59.3  11.3         2ND   1.0  2015       1  \n",
      "2  ...  54.7  46.8  35.2  33.2   65.9   6.9         2ND   3.0  2018       0  \n",
      "3  ...  52.8  41.9  36.5  29.7   67.5   7.0         2ND   3.0  2019       0  \n",
      "4  ...  56.3  40.0  38.2  29.0   71.5   7.7         2ND   1.0  2017       1  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "## ============================\n",
    "# 2. Data Preprocessing\n",
    "# =============================\n",
    "\n",
    "# Set pandas option to opt-in to future behavior for downcasting\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Load the dataset (ensure the path to your CSV is correct)\n",
    "file_path = 'cbb.csv'  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Add a new column 'windex' based on WAB (assuming WAB column exists in your data)\n",
    "df['windex'] = np.where(df['WAB'] > 7, 'True', 'False')\n",
    "\n",
    "# Replace 'True'/'False' with numeric values (0 and 1)\n",
    "df['windex'] = df['windex'].replace({'False': 0, 'True': 1})\n",
    "\n",
    "# Display the first few rows to check the changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. Feature Selection\n",
    "# ============================\n",
    "\n",
    "# Feature selection\n",
    "features = ['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D', \n",
    "            'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', \n",
    "            '3P_O', '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']\n",
    "X = df1[features]\n",
    "y = df1['POSTSEASON']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. Normalize the Data\n",
    "# ============================\n",
    "\n",
    "# Normalize the features\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (112, 21), Validation set: (28, 21)\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 5. Train/Test Split\n",
    "# ============================\n",
    "\n",
    "# Split data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print(f\"Train set: {X_train.shape}, Validation set: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.25\n",
      "KNN F1-Score: 0.19890873015873017\n",
      "KNN Jaccard Index: 0.11797026502908857\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 6. K-Nearest Neighbors (KNN) Model\n",
    "# ============================\n",
    "\n",
    "# K-Nearest Neighbors (KNN)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_val)\n",
    "\n",
    "# Metrics for KNN\n",
    "acc_knn = accuracy_score(y_val, y_pred_knn)\n",
    "f1_knn = f1_score(y_val, y_pred_knn, average='weighted')\n",
    "jaccard_knn = jaccard_score(y_val, y_pred_knn, average='weighted')\n",
    "\n",
    "print(f\"KNN Accuracy: {acc_knn}\")\n",
    "print(f\"KNN F1-Score: {f1_knn}\")\n",
    "print(f\"KNN Jaccard Index: {jaccard_knn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.4642857142857143\n",
      "Decision Tree F1-Score: 0.32882882882882886\n",
      "Decision Tree Jaccard Index: 0.23763736263736265\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 7. Decision Tree Model\n",
    "# ============================\n",
    "\n",
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=4)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred_tree = tree.predict(X_val)\n",
    "\n",
    "# Metrics for Decision Tree\n",
    "acc_tree = accuracy_score(y_val, y_pred_tree)\n",
    "f1_tree = f1_score(y_val, y_pred_tree, average='weighted')\n",
    "jaccard_tree = jaccard_score(y_val, y_pred_tree, average='weighted')\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {acc_tree}\")\n",
    "print(f\"Decision Tree F1-Score: {f1_tree}\")\n",
    "print(f\"Decision Tree Jaccard Index: {jaccard_tree}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.39285714285714285\n",
      "SVM F1-Score: 0.22161172161172163\n",
      "SVM Jaccard Index: 0.15433673469387754\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 8. Support Vector Machine (SVM) Model\n",
    "# ============================\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_val)\n",
    "\n",
    "# Metrics for SVM\n",
    "acc_svm = accuracy_score(y_val, y_pred_svm)\n",
    "f1_svm = f1_score(y_val, y_pred_svm, average='weighted')\n",
    "jaccard_svm = jaccard_score(y_val, y_pred_svm, average='weighted')\n",
    "\n",
    "print(f\"SVM Accuracy: {acc_svm}\")\n",
    "print(f\"SVM F1-Score: {f1_svm}\")\n",
    "print(f\"SVM Jaccard Index: {jaccard_svm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5714285714285714\n",
      "Logistic Regression F1-Score: 0.5240575396825397\n",
      "Logistic Regression Jaccard Index: 0.3670068027210884\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 9. Logistic Regression Model\n",
    "# ============================\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(C=0.01, solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_val)\n",
    "\n",
    "# Metrics for Logistic Regression\n",
    "acc_lr = accuracy_score(y_val, y_pred_lr)\n",
    "f1_lr = f1_score(y_val, y_pred_lr, average='weighted')\n",
    "jaccard_lr = jaccard_score(y_val, y_pred_lr, average='weighted')\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr}\")\n",
    "print(f\"Logistic Regression F1-Score: {f1_lr}\")\n",
    "print(f\"Logistic Regression Jaccard Index: {jaccard_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Model Metrics:\n",
      "KNN Accuracy: 0.25, F1-Score: 0.19890873015873017, Jaccard Index: 0.11797026502908857\n",
      "Decision Tree Accuracy: 0.4642857142857143, F1-Score: 0.32882882882882886, Jaccard Index: 0.23763736263736265\n",
      "SVM Accuracy: 0.39285714285714285, F1-Score: 0.22161172161172163, Jaccard Index: 0.15433673469387754\n",
      "Logistic Regression Accuracy: 0.5714285714285714, F1-Score: 0.5240575396825397, Jaccard Index: 0.3670068027210884\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 10. Summary of Results\n",
    "# ============================\n",
    "\n",
    "# Report for the models\n",
    "print(\"Summary of Model Metrics:\")\n",
    "print(f\"KNN Accuracy: {acc_knn}, F1-Score: {f1_knn}, Jaccard Index: {jaccard_knn}\")\n",
    "print(f\"Decision Tree Accuracy: {acc_tree}, F1-Score: {f1_tree}, Jaccard Index: {jaccard_tree}\")\n",
    "print(f\"SVM Accuracy: {acc_svm}, F1-Score: {f1_svm}, Jaccard Index: {jaccard_svm}\")\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr}, F1-Score: {f1_lr}, Jaccard Index: {jaccard_lr}\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
